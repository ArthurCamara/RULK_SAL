{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ce8331d-b878-47f8-87ad-8795933e3718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T16:29:03.567504Z",
     "start_time": "2022-06-28T16:29:03.558164Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-30T09:58:57.499704Z",
     "iopub.status.busy": "2022-06-30T09:58:57.499093Z",
     "iopub.status.idle": "2022-06-30T09:58:57.509436Z",
     "shell.execute_reply": "2022-06-30T09:58:57.508405Z",
     "shell.execute_reply.started": "2022-06-30T09:58:57.499648Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import urllib\n",
    "\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import yake\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import kendalltau, pearsonr, spearmanr\n",
    "from sklearn import preprocessing as skp\n",
    "from tqdm.auto import tqdm\n",
    "from utils import rawcount"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a296202-1e7c-46c0-af43-a57f07bf1cf3",
   "metadata": {},
   "source": [
    "# Extract keywords from Wikipedia text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "762865c6-0f10-4838-a830-fdee2264d136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T09:58:57.763040Z",
     "iopub.status.busy": "2022-06-30T09:58:57.762617Z",
     "iopub.status.idle": "2022-06-30T09:58:57.771524Z",
     "shell.execute_reply": "2022-06-30T09:58:57.770168Z",
     "shell.execute_reply.started": "2022-06-30T09:58:57.762999Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "max_n_grams = 3\n",
    "\n",
    "kw_extractor = yake.KeywordExtractor(n=max_n_grams, top=top_k * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "598428fd-36bb-4275-9056-9e2e98039da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T09:58:57.871381Z",
     "iopub.status.busy": "2022-06-30T09:58:57.870834Z",
     "iopub.status.idle": "2022-06-30T09:58:57.887832Z",
     "shell.execute_reply": "2022-06-30T09:58:57.887077Z",
     "shell.execute_reply.started": "2022-06-30T09:58:57.871328Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def normalize(v):\n",
    "    return skp.normalize(v.reshape(1, -1)).flatten()\n",
    "    \n",
    "\n",
    "def stem_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    if isinstance(text, list):\n",
    "        return [stemmer.stem(x) for x in text]\n",
    "    return [stemmer.stem(x) for x in text.split()]\n",
    "\n",
    "\n",
    "def get_kw(text, return_scores=False):\n",
    "    if return_scores:\n",
    "        return kw_extractor.extract_keywords(text)\n",
    "\n",
    "    return [x[0] for x in kw_extractor.extract_keywords(text)]\n",
    "\n",
    "\n",
    "def get_all_n_grams(text, n_max=1):\n",
    "    all_grams = []\n",
    "    for n in range(1, n_max + 1):\n",
    "        all_grams += [\" \".join(x) for x in ngrams(text, n=n)]\n",
    "    return all_grams\n",
    "\n",
    "\n",
    "def clean_text_yake(text):\n",
    "    c_text = text.lower().replace(\"\\t\\n\", \" \")\n",
    "    c_text = re.sub(r\"[^ \\w+]\", \"\", c_text)\n",
    "    tokens = word_tokenize(c_text)\n",
    "    return c_text\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    c_text = text.lower().replace(\"-\", \" \")\n",
    "    # c_text = text.lower().replace(\"\\t\\n\", \" \")  # lowecase, remove tabs and new lines\n",
    "    c_text = re.sub(r\"[^ \\w+]\", \"\", c_text)  # remove punctuations and non-alpha\n",
    "\n",
    "    tokens = word_tokenize(c_text)\n",
    "    filtered_sentence = [stemmer.stem(w) for w in tokens if w not in stop_words]\n",
    "    return filtered_sentence\n",
    "\n",
    "\n",
    "def wordcount(text):\n",
    "    text = text.lower()\n",
    "    text = text.replace(\"-\", \" \")\n",
    "    text = re.sub(\"[^\\w ]\", \"\", text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    filtered_sentence = \"\"\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence = filtered_sentence + \" \" + stemmer.stem(w)\n",
    "    words = filtered_sentence.split(\" \")\n",
    "\n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65849563-8c0b-4886-9cc5-1ec8bc61f2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T09:58:58.026531Z",
     "iopub.status.busy": "2022-06-30T09:58:58.025990Z",
     "iopub.status.idle": "2022-06-30T09:58:59.975716Z",
     "shell.execute_reply": "2022-06-30T09:58:59.974679Z",
     "shell.execute_reply.started": "2022-06-30T09:58:58.026478Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keywords_yake = {}\n",
    "tks_s = {}\n",
    "tks_s_norm = {}\n",
    "\n",
    "tks_s_no_sw = {}\n",
    "tks_s_no_sw_norm = {}\n",
    "\n",
    "remove_sw = False  # If True, Dima mode. If false, my\n",
    "\n",
    "for l in open(\"../data/wikipedia_texts.tsv\"):\n",
    "    topic, text = l.strip().split(\"\\t\", maxsplit=1)\n",
    "\n",
    "    kws = get_kw(clean_text_yake(text))  # Get keywords with YAKE\n",
    "    kws = stem_text(\" \".join(kws))  # Stem keywords\n",
    "    kws = list(dict.fromkeys(kws))[:10]  # Remove duplicates, get only the top-10\n",
    "    assert len(set(kws)) == 10\n",
    "\n",
    "    # c_no_sw = {k:v for k,v in wordcount(text).items() if k in kws}\n",
    "    # assert len((set(kws)).difference(set(c_no_sw.keys()))) == 0  # Make sure there are no 0s here\n",
    "    # tks_s_no_sw[topic] = np.asarray([c_no_sw[x] for x in kws])  # Ensure order of \"embedding\" and save in dict\n",
    "    # tks_s_no_sw_norm[topic] = normalize(tks_s_no_sw[topic])\n",
    "    \n",
    "    all_n_grams = get_all_n_grams(stem_text(clean_text_yake(text)))\n",
    "    c = Counter([x for x in all_n_grams if x in kws])  # Count occurences within the text\n",
    "    assert len((set(kws)).difference(set(c.keys()))) == 0  # Make sure there are no 0s here\n",
    "    \n",
    "    tks_s[topic] = np.asarray([c[x] for x in kws])  # Ensure order of \"embedding\" and save in dict\n",
    "    tks_s_norm[topic] = normalize(tks_s[topic])  # Normalize\n",
    "    \n",
    "    \n",
    "    keywords_yake[topic] = kws  # store kws in a dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b167afaf-88b3-4532-91aa-999d832b63b7",
   "metadata": {},
   "source": [
    "# Embeddings of clicked documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e41b0dc-a158-4b8d-b561-7bf17c2e4b75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T10:04:24.990894Z",
     "iopub.status.busy": "2022-06-30T10:04:24.990273Z",
     "iopub.status.idle": "2022-06-30T10:05:00.114263Z",
     "shell.execute_reply": "2022-06-30T10:05:00.113298Z",
     "shell.execute_reply.started": "2022-06-30T10:04:24.990841Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73256663ea64794825d2b136eab867a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1074 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "docs_yake_embeddings = defaultdict(lambda: {})\n",
    "# docs_yake_embeddings_dima = defaultdict(lambda: {})\n",
    "docs_yake_embeddings_norm = defaultdict(lambda: {})\n",
    "\n",
    "docs_file = \"../data/clicked_docs.tsv\"\n",
    "doc_topics = pickle.load(open(\"../data/doc_topics.pkl\", 'rb'))\n",
    "\n",
    "for idx, line in tqdm(enumerate(open(docs_file)), total=rawcount(docs_file)):\n",
    "    \n",
    "    url, text = line.strip().split(\"\\t\", maxsplit=1)\n",
    "    topic = doc_topics[url]\n",
    "    all_n_grams = get_all_n_grams(stem_text(clean_text_yake(text)))\n",
    "    c = Counter([x for x in all_n_grams if x in keywords_yake[topic]])\n",
    "    docs_yake_embeddings[url] = np.asarray([c[x] for x in keywords_yake[topic]])\n",
    "    docs_yake_embeddings_norm[url] = normalize(docs_yake_embeddings[url])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f0e2bb-594d-4e1e-ad9f-44d65d84895f",
   "metadata": {},
   "source": [
    "# Knowledge estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b80c463e-313c-4314-90ed-cce558d19628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T10:05:32.221751Z",
     "iopub.status.busy": "2022-06-30T10:05:32.221150Z",
     "iopub.status.idle": "2022-06-30T10:05:32.239857Z",
     "shell.execute_reply": "2022-06-30T10:05:32.238968Z",
     "shell.execute_reply.started": "2022-06-30T10:05:32.221693Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalized = True\n",
    "users_knowledge = []\n",
    "dataset = json.load(open(\"../data/logs_with_position.json\"))\n",
    "final_knowledges = defaultdict(OrderedDict)\n",
    "final_knowledges_norm = defaultdict(OrderedDict)\n",
    "valid_urls = docs_yake_embeddings.keys()\n",
    "f_dist = cosine\n",
    "\n",
    "def trim_upper_limit(cks, tks):\n",
    "    return np.asarray([min(cks[i], tks[i]) for i in range(len(cks))])\n",
    "embeddings_wiki_dima = pickle.load(open(\"dima_wiki_emb.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1149de83-166a-4b9b-b675-e147a430b0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T10:11:29.808995Z",
     "iopub.status.busy": "2022-06-30T10:11:29.808156Z",
     "iopub.status.idle": "2022-06-30T10:11:29.872380Z",
     "shell.execute_reply": "2022-06-30T10:11:29.871205Z",
     "shell.execute_reply.started": "2022-06-30T10:11:29.808936Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7011a7edbdb4b448ba249fa99be60b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simpler implementation, sum all around only.\n",
    "\n",
    "missing_docs = set()\n",
    "\n",
    "targets = tks_s\n",
    "\n",
    "embs = docs_yake_embeddings\n",
    "wiki_embs = tks_s\n",
    "final_knowledges = OrderedDict()\n",
    "\n",
    "for u in tqdm(dataset):\n",
    "    u_id = u[\"userID\"]\n",
    "    ALG = u[\"ALG\"]\n",
    "    RPL = u[\"RPL\"]\n",
    "    user_knowledge = np.zeros(10)  # initialize knowledge as zeros.\n",
    "    topic = urllib.parse.quote(u[\"topic_title\"])\n",
    "\n",
    "    for d in u[\"clicks\"]:\n",
    "        url = d[\"url\"]\n",
    "        if url not in embs:\n",
    "            missing_docs.add(url)\n",
    "            continue\n",
    "        user_knowledge += embs[url]\n",
    "        \n",
    "\n",
    "    final_knowledges[u_id] = {\"RPL\": RPL, \"ALG\": ALG, \"estimated\": 1 - f_dist(user_knowledge, targets[topic])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7de7173-35c3-4637-b695-b9d54472f53a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-30T10:12:15.703921Z",
     "iopub.status.busy": "2022-06-30T10:12:15.703227Z",
     "iopub.status.idle": "2022-06-30T10:12:15.721858Z",
     "shell.execute_reply": "2022-06-30T10:12:15.720399Z",
     "shell.execute_reply.started": "2022-06-30T10:12:15.703861Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.3085872421042087, 0.0004159256441952825)\n",
      "missing docs: 33\n"
     ]
    }
   ],
   "source": [
    "u_ids = final_knowledges.keys()\n",
    "RPLs = [final_knowledges[u][\"RPL\"] for u in u_ids]\n",
    "results = [final_knowledges[u][\"estimated\"] for u in u_ids]\n",
    "pearsons = pearsonr(results, RPLs)\n",
    "print(pearsons)\n",
    "print(f\"missing docs: {len(missing_docs)}\")\n",
    "\n",
    "pickle.dump(dict(final_knowledges), open(f\"../data/KW_knowledge_gains.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a581abc5-f121-4bfc-a491-0ecb530e12b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T17:49:44.963465Z",
     "iopub.status.busy": "2022-06-29T17:49:44.962913Z",
     "iopub.status.idle": "2022-06-29T17:49:45.044537Z",
     "shell.execute_reply": "2022-06-29T17:49:45.043802Z",
     "shell.execute_reply.started": "2022-06-29T17:49:44.963411Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675febc25fe54513ad2b3be520975147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# doc_embeddings = docs_yake_embeddings_dima[3]\n",
    "doc_embeddings = docs_yake_embeddings\n",
    "# doc_embeddings = embeddings_dima\n",
    "\n",
    "\n",
    "targets = tks_s\n",
    "# targets = embeddings_wiki_dima\n",
    "\n",
    "for u in tqdm(dataset):\n",
    "    u_id = u[\"userID\"]\n",
    "    ALG = u[\"ALG\"]\n",
    "    RPL = u[\"RPL\"]\n",
    "    topic = urllib.parse.quote(u[\"topic_title\"])\n",
    "    cks_s = {i: np.asarray([0] * len(keywords_yake[i][topic])) for i in n_grams_to_consider}\n",
    "    # cks_s_norm = {i: [0] * len(keywords_yake[i][topic]) for i in n_grams_to_consider}\n",
    "\n",
    "    cks_s_ceil = {i: np.asarray([0] * len(keywords_yake[i][topic])) for i in n_grams_to_consider}\n",
    "    # cks_s_ceil_norm = {i: [0] * len(keywords_yake[i][topic]) for i in n_grams_to_consider}\n",
    "\n",
    "    for d in u[\"clicks\"]:\n",
    "        url = d[\"url\"]\n",
    "        if url not in valid_urls:\n",
    "            continue\n",
    "        for i in n_grams_to_consider:\n",
    "\n",
    "            cks_s[i] += np.asarray(doc_embeddings[url])\n",
    "            cks_s_ceil[i] += np.asarray(trim_upper_limit(doc_embeddings[url], tks_s[i][topic]))\n",
    "\n",
    "            # cks_s_norm[i] += docs_yake_embeddings_norm[i][url]\n",
    "            # cks_s_ceil_norm[i] += trim_upper_limit(docs_yake_embeddings_norm[i][url], tks_s_norm[i][topic])\n",
    "\n",
    "    for i in n_grams_to_consider:\n",
    "        final_knowledges[f\"{i}\"][u_id] = {\n",
    "            \"RPL\": RPL,\n",
    "            \"ALG\": ALG,\n",
    "            \"final_sim\": 1 - f_dist(cks_s[i], tks_s[i][topic]),\n",
    "        }\n",
    "        # final_knowledges[f\"{i}_norm\"][u_id] = {\n",
    "        #     \"RPL\": RPL,\n",
    "        #     \"ALG\": ALG,\n",
    "        #     \"final_sim\": 1 - f_dist(cks_s_norm[i], tks_s_norm[i][topic]),\n",
    "        # }\n",
    "        final_knowledges[f\"{i}_ceil\"][u_id] = {\n",
    "            \"RPL\": RPL,\n",
    "            \"ALG\": ALG,\n",
    "            \"final_sim\": 1 - f_dist(cks_s_ceil[i], tks_s[i][topic]),\n",
    "        }\n",
    "        # final_knowledges[f\"{i}_ceil_norm\"][u_id] = {\n",
    "        #     \"RPL\": RPL,\n",
    "        #     \"ALG\": ALG,\n",
    "        #     \"final_sim\": 1 - f_dist(cks_s_ceil_norm[i], tks_s_norm[i][topic]),\n",
    "        # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8f3c86dd-dcab-425f-84b3-e108ab2d3ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T17:49:47.210805Z",
     "iopub.status.busy": "2022-06-29T17:49:47.210251Z",
     "iopub.status.idle": "2022-06-29T17:49:47.225803Z",
     "shell.execute_reply": "2022-06-29T17:49:47.224737Z",
     "shell.execute_reply.started": "2022-06-29T17:49:47.210752Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3', (0.311954498627866, 0.00035655478368730453)),\n",
      " ('3_ceil', (0.22128421222987416, 0.012413527912592178))]\n"
     ]
    }
   ],
   "source": [
    "RPLs = []\n",
    "ALGs = []\n",
    "u_ids = [u[\"userID\"] for u in dataset]\n",
    "\n",
    "pearsons_RPL = {}\n",
    "corr_ALG = {}\n",
    "\n",
    "for m in final_knowledges:\n",
    "    u_ids = final_knowledges[m].keys()\n",
    "    ALGs = [final_knowledges[m][u][\"ALG\"] for u in u_ids]\n",
    "    RPLs = [final_knowledges[m][u][\"RPL\"] for u in u_ids]\n",
    "    results = [final_knowledges[m][u][\"final_sim\"] for u in u_ids]\n",
    "\n",
    "    # results = [_users[x][\"final_sim\"] for x in u_ids if x in _users]\n",
    "    pearsons_RPL[m] = pearsonr(results, RPLs)\n",
    "    # pearsons_ALG[m] = pearsonr(results, ALGs)\n",
    "\n",
    "pprint(sorted(pearsons_RPL.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "03230e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T16:29:55.500420Z",
     "start_time": "2022-06-28T16:29:55.485148Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-29T17:49:51.408109Z",
     "iopub.status.busy": "2022-06-29T17:49:51.407557Z",
     "iopub.status.idle": "2022-06-29T17:49:51.421593Z",
     "shell.execute_reply": "2022-06-29T17:49:51.420237Z",
     "shell.execute_reply.started": "2022-06-29T17:49:51.408056Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(dict(final_knowledges), open(f\"../data/Arthur_KW_Knowledges.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESIRES",
   "language": "python",
   "name": "desires"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
