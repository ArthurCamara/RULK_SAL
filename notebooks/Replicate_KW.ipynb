{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ce8331d-b878-47f8-87ad-8795933e3718",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T16:29:03.567504Z",
     "start_time": "2022-06-28T16:29:03.558164Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-29T14:57:00.617519Z",
     "iopub.status.busy": "2022-06-29T14:57:00.616920Z",
     "iopub.status.idle": "2022-06-29T14:57:00.628560Z",
     "shell.execute_reply": "2022-06-29T14:57:00.627282Z",
     "shell.execute_reply.started": "2022-06-29T14:57:00.617465Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import urllib\n",
    "\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import yake\n",
    "\n",
    "from nltk import ngrams\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import kendalltau, pearsonr, spearmanr\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a296202-1e7c-46c0-af43-a57f07bf1cf3",
   "metadata": {},
   "source": [
    "# Extract keywords from Wikipedia text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "762865c6-0f10-4838-a830-fdee2264d136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T15:12:13.928902Z",
     "iopub.status.busy": "2022-06-28T15:12:13.928334Z",
     "iopub.status.idle": "2022-06-28T15:12:13.938995Z",
     "shell.execute_reply": "2022-06-28T15:12:13.937665Z",
     "shell.execute_reply.started": "2022-06-28T15:12:13.928848Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "top_k = 10\n",
    "max_n_grams = 3\n",
    "\n",
    "kw_extractors = [None]\n",
    "kw_extractors += [yake.KeywordExtractor(n=i + 1, top=top_k * 2) for i in range(max_n_grams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "598428fd-36bb-4275-9056-9e2e98039da4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T17:10:22.089176Z",
     "iopub.status.busy": "2022-06-29T17:10:22.088502Z",
     "iopub.status.idle": "2022-06-29T17:10:22.108212Z",
     "shell.execute_reply": "2022-06-29T17:10:22.107326Z",
     "shell.execute_reply.started": "2022-06-29T17:10:22.089119Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "def stem_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    if isinstance(text, list):\n",
    "        return [stemmer.stem(x) for x in text]\n",
    "    return [stemmer.stem(x) for x in text.split()]\n",
    "\n",
    "\n",
    "def get_kw(text, max_ngram_size=2, return_scores=False):\n",
    "    if return_scores:\n",
    "        return kw_extractors[max_ngram_size].extract_keywords(text)\n",
    "\n",
    "    return [x[0] for x in kw_extractors[max_ngram_size].extract_keywords(text)]\n",
    "\n",
    "\n",
    "def get_all_n_grams(text, n_max=1):\n",
    "    all_grams = []\n",
    "    for n in range(1, n_max + 1):\n",
    "        all_grams += [\" \".join(x) for x in ngrams(text, n=n)]\n",
    "    return all_grams\n",
    "\n",
    "\n",
    "def clean_text_yake(text):\n",
    "    c_text =  text.lower().replace(\"\\t\\n\", \" \")\n",
    "    c_text = re.sub(r\"[^ \\w+]\", \"\", c_text)\n",
    "    tokens = word_tokenize(c_text)\n",
    "    return c_text\n",
    "\n",
    "def clean_text(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    c_text = text.lower().replace(\"-\", \" \")\n",
    "    # c_text = text.lower().replace(\"\\t\\n\", \" \")  # lowecase, remove tabs and new lines\n",
    "    c_text = re.sub(r\"[^ \\w+]\", \"\", c_text)  # remove punctuations and non-alpha\n",
    "\n",
    "    tokens = word_tokenize(c_text)\n",
    "    filtered_sentence = [stemmer.stem(w) for w in tokens if w not in stop_words]\n",
    "    return filtered_sentence\n",
    "\n",
    "\n",
    "def wordcount(text):\n",
    "    text = text.lower()\n",
    "    text  = text.replace(\"-\", \" \")\n",
    "    text = re.sub(\"[^\\w ]\", \"\", text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    filtered_sentence = \"\"\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence = filtered_sentence + \" \" + stemmer.stem(w)\n",
    "    words = filtered_sentence.split(\" \")\n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "65849563-8c0b-4886-9cc5-1ec8bc61f2a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T15:08:13.125625Z",
     "iopub.status.busy": "2022-06-29T15:08:13.124921Z",
     "iopub.status.idle": "2022-06-29T15:08:14.894487Z",
     "shell.execute_reply": "2022-06-29T15:08:14.893648Z",
     "shell.execute_reply.started": "2022-06-29T15:08:13.125566Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keywords_yake = defaultdict(lambda: {})\n",
    "tks_s = defaultdict(lambda: {})\n",
    "tks_s_norm = defaultdict(lambda: {})\n",
    "\n",
    "remove_sw = True #IF True, Dima mode. If false, my\n",
    "\n",
    "for l in open(\"../data/wikipedia_texts.tsv\"):\n",
    "    topic, text = l.strip().split(\"\\t\", maxsplit=1)\n",
    "\n",
    "    if not remove_sw:\n",
    "        all_n_grams = get_all_n_grams(stem_text(clean_text_yake(text)))\n",
    "        \n",
    "    for i in n_grams_to_consider:\n",
    "        kws = get_kw(clean_text_yake(text), i)  # Get keywords with YAKE\n",
    "        kws = stem_text(\" \".join(kws))  # Stem keywords\n",
    "        kws = list(dict.fromkeys(kws))[:10]  # Remove duplicates, get only the top-10\n",
    "        assert len(set(kws)) == 10\n",
    "        \n",
    "        if remove_sw:\n",
    "            counter_word = wordcount(text)\n",
    "            # c = Counter(clean_text(text))\n",
    "        else:\n",
    "            c = Counter([x for x in all_n_grams if x in kws])  # Count occurences within the text\n",
    "            assert len((set(kws)).difference(set(c.keys()))) == 0  # Make sure there is no 0s here\n",
    "        tks_s[i][topic] = np.asarray([c[x] for x in kws])  # Ensure order of \"embedding\" and save in dict\n",
    "        tks_s_norm[i][topic] = normalize(np.asarray([c[x] for x in kws]).reshape(1, -1)).flatten()  # Normalize\n",
    "        keywords_yake[i][topic] = kws  # store kws in a dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b167afaf-88b3-4532-91aa-999d832b63b7",
   "metadata": {},
   "source": [
    "# Embeddings of clicked documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9b94f9aa-4ab5-4daf-a17d-8524513ed4df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T15:23:00.578541Z",
     "iopub.status.busy": "2022-06-29T15:23:00.577903Z",
     "iopub.status.idle": "2022-06-29T15:23:00.585752Z",
     "shell.execute_reply": "2022-06-29T15:23:00.584105Z",
     "shell.execute_reply.started": "2022-06-29T15:23:00.578483Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = \"https://www.health.harvard.edu/newsletter_article/Noise-induced_hearing_loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea2416e2-943a-465f-bee3-e856d6411f5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T17:04:49.846496Z",
     "iopub.status.busy": "2022-06-29T17:04:49.845814Z",
     "iopub.status.idle": "2022-06-29T17:04:49.865453Z",
     "shell.execute_reply": "2022-06-29T17:04:49.863734Z",
     "shell.execute_reply.started": "2022-06-29T17:04:49.846438Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 0, 0, 1, 4, 1, 0, 0, 1, 2])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_yake_embeddings[i][url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5e41b0dc-a158-4b8d-b561-7bf17c2e4b75",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2022-06-29T17:27:55.918330Z",
     "iopub.status.busy": "2022-06-29T17:27:55.917769Z",
     "iopub.status.idle": "2022-06-29T17:28:51.433929Z",
     "shell.execute_reply": "2022-06-29T17:28:51.432937Z",
     "shell.execute_reply.started": "2022-06-29T17:27:55.918276Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818b1693f66048ec8276df2221e7d379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1074 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.moentcenter.com/library/4036/Noise-InducedHearingLossInChildren.html\n",
      "[13, 1, 0, 0, 11, 4, 0, 0, 0, 6]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://www.amboss.com/us/knowledge/Hearing_loss\n",
      "[68, 0, 3, 0, 52, 0, 2, 0, 0, 8]\n",
      "[3, 0, 0, 0, 3, 0, 0, 0, 0, 0]\n",
      "[3, 0, 0, 0, 3, 0, 0, 0, 0, 0]\n",
      "https://www.health.harvard.edu/newsletter_article/Noise-induced_hearing_loss\n",
      "[7, 0, 0, 1, 4, 1, 0, 0, 0, 2]\n",
      "[7, 0, 0, 1, 4, 1, 0, 0, 1, 2]\n",
      "[7, 0, 0, 1, 4, 1, 0, 0, 1, 2]\n",
      "https://www.economywatch.com/us-subprime/impact-europe.html\n",
      "[0, 9, 0, 0, 9, 4, 2, 0, 0, 2]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://www.starkey.com/blog/articles/2016/12/tinnitus-tied-to-hearing-loss\n",
      "[11, 1, 0, 0, 6, 0, 0, 0, 0, 3]\n",
      "[12, 1, 0, 0, 6, 0, 0, 0, 0, 3]\n",
      "[12, 1, 0, 0, 6, 0, 0, 0, 0, 3]\n",
      "https://www.amazon.com/Austrian-School-Business-Cycle-Theory/dp/131222827X\n",
      "[0, 0, 1, 3, 3, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 8, 7, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 8, 7, 0, 0, 0, 0, 0]\n",
      "http://www.nationalacademies.org/hmd/Activities/Veterans/MilitaryHearingLoss.aspx\n",
      "[20, 1, 0, 0, 13, 0, 0, 1, 3, 2]\n",
      "[7, 1, 0, 0, 4, 0, 0, 0, 1, 0]\n",
      "[7, 1, 0, 0, 4, 0, 0, 0, 1, 0]\n",
      "https://www.nhs.uk/conditions/irritable-bowel-syndrome-ibs/symptoms/\n",
      "[0, 9, 0, 0, 0, 0, 7, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://www.merriam-webster.com/dictionary/metaethics\n",
      "[3, 0, 0, 0, 0, 3, 0, 0, 0, 0]\n",
      "[3, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[3, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://www.learnreligions.com/ethics-descriptive-normative-and-analytic-4037543\n",
      "[21, 0, 0, 0, 0, 0, 1, 0, 0, 14]\n",
      "[19, 0, 0, 0, 0, 0, 2, 0, 0, 13]\n",
      "[19, 0, 0, 0, 0, 0, 2, 0, 0, 13]\n",
      "https://www.nhs.uk/conditions/irritable-bowel-syndrome-ibs/diet-lifestyle-and-medicines/\n",
      "[0, 10, 0, 0, 0, 1, 5, 0, 0, 0]\n",
      "[0, 2, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 2, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "https://www.thoughtco.com/what-is-radiocarbon-dating-172525\n",
      "[0, 2, 0, 0, 2, 0, 11, 0, 0, 7]\n",
      "[0, 2, 0, 0, 2, 0, 12, 0, 0, 7]\n",
      "[0, 2, 0, 0, 2, 0, 11, 0, 0, 6]\n",
      "https://www.uptodate.com/contents/etiology-of-hearing-loss-in-adults#!\n",
      "[12, 0, 0, 0, 10, 1, 0, 0, 1, 2]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://www.nhs.uk/conditions/irritable-bowel-syndrome-ibs/\n",
      "[0, 5, 0, 0, 0, 0, 2, 0, 0, 0]\n",
      "[0, 2, 0, 0, 0, 0, 2, 0, 0, 0]\n",
      "[0, 2, 0, 0, 0, 0, 2, 0, 0, 0]\n",
      "https://www.wikem.org/wiki/Irritable_bowel_syndrome\n",
      "[0, 2, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://www.webmd.com/ibs/guide/irritable-bowel-syndrome-symptoms-types\n",
      "[0, 7, 0, 0, 0, 0, 4, 0, 0, 0]\n",
      "[0, 2, 0, 0, 0, 0, 3, 0, 0, 0]\n",
      "[0, 2, 0, 0, 0, 0, 3, 0, 0, 0]\n",
      "https://www.dictionary.com/browse/ethic\n",
      "[31, 1, 1, 0, 1, 5, 0, 0, 0, 0]\n",
      "[16, 1, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "[16, 1, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "https://ethicsunwrapped.utexas.edu/\n",
      "[18, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[4, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[4, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://ethicsunwrapped.utexas.edu/glossary\n",
      "[32, 2, 3, 0, 0, 0, 0, 0, 0, 1]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://study.com/academy/practice/quiz-worksheet-the-business-cycle-in-economics.html\n",
      "[0, 0, 3, 12, 12, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://www.thoughtco.com/real-business-cycle-theory-1147122\n",
      "[0, 0, 0, 14, 16, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 20, 20, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 20, 20, 0, 0, 0, 0, 0]\n",
      "https://www.medicaleconomics.com/medical\n",
      "[0, 0, 9, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 4, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://www.medicaleconomics.com/\n",
      "[0, 0, 2, 0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://www.webmd.com/ibs/qa/what-triggers-irritable-bowel-syndrome\n",
      "[0, 16, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "https://www.webmd.com/ibs/guide/irritable-bowel-syndrome-treatment-care\n",
      "[0, 13, 0, 0, 0, 0, 4, 0, 0, 0]\n",
      "[0, 8, 0, 0, 0, 0, 2, 0, 0, 0]\n",
      "[0, 6, 0, 0, 0, 0, 2, 0, 0, 0]\n",
      "https://www.learnreligions.com/virtue-ethics-morality-and-character-249866\n",
      "[23, 0, 32, 0, 0, 0, 0, 0, 0, 0]\n",
      "[21, 0, 31, 0, 0, 0, 1, 0, 0, 0]\n",
      "[21, 0, 29, 0, 0, 0, 1, 0, 0, 0]\n",
      "https://www.dictionary.com/browse/radiocarbon\n",
      "[0, 0, 0, 0, 0, 1, 6, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "https://commons.wikimedia.org/wiki/Category:Business_cycle\n",
      "[0, 0, 1, 6, 10, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 3, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 3, 0, 0, 0, 0, 0]\n",
      "https://www.thoughtco.com/phases-of-the-business-cycle-1146345\n",
      "[0, 0, 0, 14, 16, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 13, 15, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 13, 15, 0, 0, 0, 0, 0]\n",
      "https://www.businesscycle.com/\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "https://www.businesscycle.com/ecri-news-events/news\n",
      "[0, 0, 9, 1, 2, 0, 0, 1, 0, 0]\n",
      "[0, 0, 4, 1, 2, 0, 0, 1, 0, 0]\n",
      "[0, 0, 4, 1, 2, 0, 0, 1, 0, 0]\n",
      "https://www.telegraph.co.uk/finance/2815755/Timeline-The-sub-prime-mortgage-crisis.html\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[3, 1, 0, 0, 0, 3, 2, 2, 3, 4]\n",
      "[3, 1, 0, 0, 5, 3, 2, 2, 3, 4]\n",
      "https://www.khanacademy.org/economics-finance-domain/macroeconomics\n",
      "[0, 0, 4, 9, 9, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "https://www.dictionary.com/browse/biogenetic\n",
      "[0, 0, 0, 8, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 4, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 4, 0, 0, 0, 0, 0, 0]\n",
      "https://megsmenopause.com/2020/01/29/ibs/\n",
      "[2, 16, 0, 0, 0, 2, 12, 0, 0, 0]\n",
      "[2, 18, 0, 0, 0, 2, 13, 0, 0, 0]\n",
      "[2, 17, 0, 0, 0, 2, 13, 0, 0, 0]\n",
      "https://www.managedcaremag.com/archives/2016/2/economic-evaluation-linaclotide-treatment-adult-patients-chronic-idiopathic\n",
      "[5, 3, 58, 1, 0, 1, 4, 0, 6, 0]\n",
      "[5, 3, 59, 1, 0, 1, 4, 0, 6, 0]\n",
      "[5, 0, 53, 1, 0, 1, 4, 0, 6, 0]\n",
      "https://www.mdpi.com/1660-4601/17/4/1201/htm\n",
      "[18, 1, 1, 9, 14, 0, 4, 0, 4, 2]\n",
      "[21, 1, 1, 8, 14, 0, 4, 0, 5, 2]\n",
      "[21, 1, 1, 8, 14, 0, 4, 0, 5, 2]\n"
     ]
    }
   ],
   "source": [
    "docs_yake_embeddings = defaultdict(lambda: {})\n",
    "docs_yake_embeddings_dima = defaultdict(lambda: {})\n",
    "# docs_yake_embeddings_norm = defaultdict(lambda: {})\n",
    "i = 3\n",
    "for idx, line in tqdm(enumerate(open(\"../data/clicked_docs_with_topics.tsv\")), total=1074):\n",
    "    url, topic, text = line.strip().split(\"\\t\", maxsplit=2)\n",
    "    all_n_grams = get_all_n_grams(stem_text(clean_text_yake(text)))\n",
    "    c = Counter([x for x in all_n_grams if x in keywords_yake[i][topic]])\n",
    "    my_embedding = [c[x] for x in keywords_yake[i][topic]]\n",
    "    docs_yake_embeddings[i][url] = my_embedding\n",
    "    \n",
    "    c = Counter([x for x in clean_text(text) if x in keywords_yake[i][topic]])\n",
    "    vect = []\n",
    "    for n in keywords_yake[i][topic]:\n",
    "        occ = int((c[n]))\n",
    "        vect.append(occ)\n",
    "    \n",
    "    docs_yake_embeddings_dima[i][url] = vect\n",
    "    if vect != embeddings_dima[url]:\n",
    "        print(url)\n",
    "        print(embeddings_dima[url]) \n",
    "        print(vect)\n",
    "        print(docs_yake_embeddings[i][url])\n",
    "                               \n",
    "    continue\n",
    "    if idx > 1:\n",
    "        break\n",
    "    if not remove_sw: # My mode\n",
    "        all_n_grams = get_all_n_grams(stem_text(clean_text(text)))\n",
    "\n",
    "    for i in n_grams_to_consider:\n",
    "        if remove_sw:\n",
    "            c = Counter(clean_text(text))\n",
    "        else:\n",
    "            c = Counter([x for x in all_n_grams if x in keywords_yake[i][topic]])\n",
    "        docs_yake_embeddings[i][url] = np.asarray([c[x] for x in keywords_yake[i][topic]])\n",
    "        # docs_yake_embeddings_norm[i][url] = normalize(docs_yake_embeddings[i][url].reshape(1, -1)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "cfecd139-becc-427b-8729-4686ace8f3f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T17:14:00.501942Z",
     "iopub.status.busy": "2022-06-29T17:14:00.501211Z",
     "iopub.status.idle": "2022-06-29T17:14:00.511723Z",
     "shell.execute_reply": "2022-06-29T17:14:00.510366Z",
     "shell.execute_reply.started": "2022-06-29T17:14:00.501883Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_dima = pickle.load(open(\"dima_emb.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f0e2bb-594d-4e1e-ad9f-44d65d84895f",
   "metadata": {},
   "source": [
    "# Knowledge estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b80c463e-313c-4314-90ed-cce558d19628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T17:49:43.186643Z",
     "iopub.status.busy": "2022-06-29T17:49:43.186087Z",
     "iopub.status.idle": "2022-06-29T17:49:43.203497Z",
     "shell.execute_reply": "2022-06-29T17:49:43.202272Z",
     "shell.execute_reply.started": "2022-06-29T17:49:43.186589Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalized = True\n",
    "users_knowledge = []\n",
    "dataset = json.load(open(\"../data/logs_with_position.json\"))\n",
    "final_knowledges = defaultdict(OrderedDict)\n",
    "final_knowledges_norm = defaultdict(OrderedDict)\n",
    "valid_urls = docs_yake_embeddings[i].keys()\n",
    "f_dist = cosine\n",
    "\n",
    "\n",
    "def trim_upper_limit(cks, tks):\n",
    "    return np.asarray([min(cks[i], tks[i]) for i in range(len(cks))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5327e15b-8f3d-4840-8f3c-52a3ffcb8c8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T17:49:44.291058Z",
     "iopub.status.busy": "2022-06-29T17:49:44.290503Z",
     "iopub.status.idle": "2022-06-29T17:49:44.298414Z",
     "shell.execute_reply": "2022-06-29T17:49:44.297059Z",
     "shell.execute_reply.started": "2022-06-29T17:49:44.291005Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_wiki_dima = pickle.load(open(\"dima_wiki_emb.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a581abc5-f121-4bfc-a491-0ecb530e12b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T17:49:44.963465Z",
     "iopub.status.busy": "2022-06-29T17:49:44.962913Z",
     "iopub.status.idle": "2022-06-29T17:49:45.044537Z",
     "shell.execute_reply": "2022-06-29T17:49:45.043802Z",
     "shell.execute_reply.started": "2022-06-29T17:49:44.963411Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675febc25fe54513ad2b3be520975147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# doc_embeddings = docs_yake_embeddings_dima[3]\n",
    "# doc_embeddings = docs_yake_embeddings[3]\n",
    "doc_embeddings = embeddings_dima\n",
    "\n",
    "targets = tks_s[3]\n",
    "targets = embeddings_wiki_dima\n",
    "\n",
    "for u in tqdm(dataset):\n",
    "    u_id = u[\"userID\"]\n",
    "    ALG = u[\"ALG\"]\n",
    "    RPL = u[\"RPL\"]\n",
    "    topic = urllib.parse.quote(u[\"topic_title\"])\n",
    "    cks_s = {i: np.asarray([0] * len(keywords_yake[i][topic])) for i in n_grams_to_consider}\n",
    "    # cks_s_norm = {i: [0] * len(keywords_yake[i][topic]) for i in n_grams_to_consider}\n",
    "\n",
    "    cks_s_ceil = {i: np.asarray([0] * len(keywords_yake[i][topic])) for i in n_grams_to_consider}\n",
    "    # cks_s_ceil_norm = {i: [0] * len(keywords_yake[i][topic]) for i in n_grams_to_consider}\n",
    "\n",
    "    for d in u[\"clicks\"]:\n",
    "        url = d[\"url\"]\n",
    "        if url not in valid_urls:\n",
    "            continue\n",
    "        for i in n_grams_to_consider:\n",
    "            # cks_s[i] += docs_yake_embeddings[i][url]\n",
    "            # cks_s_ceil[i] += trim_upper_limit(docs_yake_embeddings[i][url], tks_s[i][topic])\n",
    "            # cks_s_norm[i] += docs_yake_embeddings_norm[i][url]\n",
    "            # cks_s_ceil_norm[i] += trim_upper_limit(docs_yake_embeddings_norm[i][url], tks_s_norm[i][topic])\n",
    "\n",
    "            cks_s[i] += np.asarray(doc_embeddings[url])\n",
    "            cks_s_ceil[i] += np.asarray(trim_upper_limit(doc_embeddings[url], tks_s[i][topic]))\n",
    "            \n",
    "            # cks_s_norm[i] += docs_yake_embeddings_norm[i][url]\n",
    "            # cks_s_ceil_norm[i] += trim_upper_limit(docs_yake_embeddings_norm[i][url], tks_s_norm[i][topic])\n",
    "\n",
    "    for i in n_grams_to_consider:\n",
    "        final_knowledges[f\"{i}\"][u_id] = {\n",
    "            \"RPL\": RPL,\n",
    "            \"ALG\": ALG,\n",
    "            \"final_sim\": 1 - f_dist(cks_s[i], tks_s[i][topic]),\n",
    "        }\n",
    "        # final_knowledges[f\"{i}_norm\"][u_id] = {\n",
    "        #     \"RPL\": RPL,\n",
    "        #     \"ALG\": ALG,\n",
    "        #     \"final_sim\": 1 - f_dist(cks_s_norm[i], tks_s_norm[i][topic]),\n",
    "        # }\n",
    "        final_knowledges[f\"{i}_ceil\"][u_id] = {\n",
    "            \"RPL\": RPL,\n",
    "            \"ALG\": ALG,\n",
    "            \"final_sim\": 1 - f_dist(cks_s_ceil[i], tks_s[i][topic]),\n",
    "        }\n",
    "        # final_knowledges[f\"{i}_ceil_norm\"][u_id] = {\n",
    "        #     \"RPL\": RPL,\n",
    "        #     \"ALG\": ALG,\n",
    "        #     \"final_sim\": 1 - f_dist(cks_s_ceil_norm[i], tks_s_norm[i][topic]),\n",
    "        # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8f3c86dd-dcab-425f-84b3-e108ab2d3ff3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-29T17:49:47.210805Z",
     "iopub.status.busy": "2022-06-29T17:49:47.210251Z",
     "iopub.status.idle": "2022-06-29T17:49:47.225803Z",
     "shell.execute_reply": "2022-06-29T17:49:47.224737Z",
     "shell.execute_reply.started": "2022-06-29T17:49:47.210752Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('3', (0.311954498627866, 0.00035655478368730453)),\n",
      " ('3_ceil', (0.22128421222987416, 0.012413527912592178))]\n"
     ]
    }
   ],
   "source": [
    "RPLs = []\n",
    "ALGs = []\n",
    "u_ids = [u[\"userID\"] for u in dataset]\n",
    "\n",
    "pearsons_RPL = {}\n",
    "corr_ALG = {}\n",
    "\n",
    "for m in final_knowledges:\n",
    "    u_ids = final_knowledges[m].keys()\n",
    "    ALGs = [final_knowledges[m][u][\"ALG\"] for u in u_ids]\n",
    "    RPLs = [final_knowledges[m][u][\"RPL\"] for u in u_ids]\n",
    "    results = [final_knowledges[m][u][\"final_sim\"] for u in u_ids]\n",
    "\n",
    "    # results = [_users[x][\"final_sim\"] for x in u_ids if x in _users]\n",
    "    pearsons_RPL[m] = pearsonr(results, RPLs)\n",
    "    # pearsons_ALG[m] = pearsonr(results, ALGs)\n",
    "\n",
    "pprint(sorted(pearsons_RPL.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "03230e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-28T16:29:55.500420Z",
     "start_time": "2022-06-28T16:29:55.485148Z"
    },
    "execution": {
     "iopub.execute_input": "2022-06-29T17:49:51.408109Z",
     "iopub.status.busy": "2022-06-29T17:49:51.407557Z",
     "iopub.status.idle": "2022-06-29T17:49:51.421593Z",
     "shell.execute_reply": "2022-06-29T17:49:51.420237Z",
     "shell.execute_reply.started": "2022-06-29T17:49:51.408056Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(dict(final_knowledges), open(f\"../data/Arthur_KW_Knowledges.pkl\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESIRES",
   "language": "python",
   "name": "desires"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
