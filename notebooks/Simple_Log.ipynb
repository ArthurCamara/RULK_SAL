{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0325c404-c436-4ccc-8650-9a5ccc1cecfd",
   "metadata": {},
   "source": [
    "Creates a simpler query-log style of logs. A list with each eleement a dictionaty like this:\n",
    "```\n",
    "{\n",
    "    RPL: 0.8,\n",
    "    ALG: 0.4,\n",
    "    topic_id: 0123,\n",
    "    topic_title: \"GMO\",\n",
    "    session_duration: <time in seconds>\n",
    "    \n",
    "    queries: [ {\n",
    "        query_text: \"query text\", \n",
    "        documents_clicked: {url:\"http://....\", position:0}\n",
    "        }\n",
    "     ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3368332-8fba-4f8b-ba26-50fba24cc261",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preparation\n",
    "- See `Analysis.ipynb` for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e6c4dc5-0878-473e-a725-363520cae790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import base64\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict\n",
    "\n",
    "def p_date(x: str) -> datetime:\n",
    "    \"\"\"Short hand for datetime.fromisoformat(x)\"\"\"\n",
    "    if isinstance(x, datetime):\n",
    "        return  x\n",
    "    return datetime.fromisoformat(x)\n",
    "\n",
    "with gzip.open(\"../data/all_logs_clean.json.gz\", 'r') as inf:\n",
    "    all_logs = json.loads(inf.read().decode(\"utf-8\"))\n",
    "with gzip.open(\"../data/all_queries_clean.json.gz\", 'r') as inf:\n",
    "    all_queries = json.loads(inf.read().decode(\"utf-8\"))\n",
    "\n",
    "vocab = json.load(open(\"../data/vocab.json\")) #VKS vocabulary dictionary\n",
    "users = set([x[\"userId\"] for x in all_logs])\n",
    "\n",
    "pre_tests = {\n",
    "    **{\n",
    "        x[\"sessionId\"]: x[\"meta\"]\n",
    "        for x in all_logs if x['event'] == \"SURVEY_REGISTER_RESULTS\"\n",
    "    },\n",
    "    **{\n",
    "        x[\"userId\"]: x[\"meta\"]\n",
    "        for x in all_logs if x['event'] == \"SURVEY_REGISTER_RESULTS\"\n",
    "    },\n",
    "    **{\n",
    "        x[\"meta\"][\"data\"][\"userId\"]: x[\"meta\"]\n",
    "        for x in all_logs if x['event'] == \"SURVEY_REGISTER_RESULTS\"\n",
    "    }\n",
    "}\n",
    "prolific_path = [f\"../data/{x}\" for x in [\"prolific_export_5e4d0dea60c37d14cb329934.csv\", \"prolific_export_5e4e4f7be482212a2429a366.csv\", \"prolific_export_5f46799646aa3002de1afa25.csv\"]]\n",
    "prolific_last_time = dict()\n",
    "session_length_prolific = dict()\n",
    "prolific_status = dict()\n",
    "prolific_users = set()\n",
    "returned_code = dict()\n",
    "found = 0\n",
    "for p in prolific_path:\n",
    "    for line in open(p):\n",
    "        l = line.split(\",\")\n",
    "        if l[0] == \"session_id\":\n",
    "            continue\n",
    "        participant_id = l[1] \n",
    "        prolific_users.add(participant_id)\n",
    "        duration = float(l[5])\n",
    "        status = l[2]\n",
    "        returned_code[participant_id] = l[11]\n",
    "        prolific_status[participant_id] = status\n",
    "        prolific_last_time[participant_id] = l[4]\n",
    "        session_length_prolific[participant_id] = duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7206b-d8e6-4139-bbd2-a4bbd4314fec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "755e5a00-1def-43b7-9454-46f2dd4ef26e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ALG(user_logs: list[dict], topic: str) -> float:\n",
    "    \"\"\"Computes Absolute Learning Gains:\n",
    "    Args:\n",
    "        user_logs: sorted (by time) list with all of one user's logs\n",
    "        topic: string with user's topic id\n",
    "    \"\"\"\n",
    "    score = 0\n",
    "    topic_terms = get_topic_terms(topic)\n",
    "    pretest_results = [\n",
    "        r for r in user_logs if r[\"event\"] == \"SURVEY_PRE_TEST_RESULTS\"\n",
    "    ][0]\n",
    "    posttest_results = [\n",
    "        r for r in user_logs if r[\"event\"] == \"SURVEY_POST_TEST_RESULTS\"\n",
    "    ][0]\n",
    "    score_mapping = {1: 0, 2: 0, 3: 1, 4: 2}\n",
    "    for question in topic_terms:\n",
    "        qid = \"Q-\" + str(topic) + \"-\" + str(question)\n",
    "        pre_score = score_mapping[int(pretest_results[\"meta\"][\"data\"][qid])]\n",
    "        post_score = score_mapping[int(posttest_results[\"meta\"][\"data\"][qid])]\n",
    "        score += max(0, post_score - pre_score)\n",
    "    return score / 10\n",
    "\n",
    "\n",
    "def MLG(user_logs: list[dict], topic: str) -> float:\n",
    "    \"\"\"Computes Maximum possible learning potential\n",
    "    Args:\n",
    "        user_logs: sorted (by time) list with all of one user's logs\n",
    "        topic: string with users' topic id\n",
    "    \"\"\"\n",
    "    topic_terms = get_topic_terms(topic)\n",
    "    pretest_results = [\n",
    "        r for r in user_logs if r[\"event\"] == \"SURVEY_PRE_TEST_RESULTS\"\n",
    "    ][0]\n",
    "    score = 0\n",
    "    score_mapping = {1: 0, 2: 0, 3: 1, 4: 2}\n",
    "    for question in topic_terms:\n",
    "        qid = \"Q-\" + str(topic) + \"-\" + str(question)\n",
    "        pre_score = score_mapping[int(pretest_results[\"meta\"][\"data\"][qid])]\n",
    "        score += 2 - pre_score\n",
    "    return score / 10\n",
    "\n",
    "\n",
    "def RPL(user_logs: list, topic: str) -> float:\n",
    "    \"\"\"Computes user's Realized Potential Learning:\n",
    "    Args:\n",
    "        user_logs: List of one user's logs\n",
    "        topic: string with user's topic id \n",
    "    \"\"\"\n",
    "    sorted_logs = sorted(user_logs, key=lambda x: x[\"date\"], reverse=True)\n",
    "    _ALG = ALG(sorted_logs, topic)\n",
    "    _MLG = MLG(sorted_logs, topic)\n",
    "    return _ALG / _MLG\n",
    "\n",
    "def get_all_logs(user: str) -> list[dict]:\n",
    "    \"\"\"Get all logs from one user\"\"\"\n",
    "    user_logs = [x for x in all_logs if x[\"userId\"] == user]\n",
    "    return sorted(user_logs, key = lambda x: datetime.strptime(x[\"date\"], '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "def get_topic_title(user_logs: list[dict]) -> str:\n",
    "    \"\"\"Gets the title of the topic assigned to user\"\"\"\n",
    "    return [x for x in user_logs if x[\"event\"] == \"SURVEY_POST_TEST_RESULTS\"\n",
    "            ][0]['task']['data']['topic']['title']\n",
    "\n",
    "\n",
    "def get_topic_id(user_logs: list[dict]) -> str:\n",
    "    \"\"\"Gets the id of the topic the user was assigned to\"\"\"\n",
    "    for x in user_logs:\n",
    "        if x[\"event\"] == \"SEARCHRESULT_VIEW_URL\":\n",
    "            return x[\"task\"][\"data\"][\"topic\"][\"id\"]\n",
    "\n",
    "def get_topic_terms(p: str) -> list[str]:\n",
    "    \"\"\"Gets a list of the terms for the VKS for a given topic id\"\"\"\n",
    "    return vocab[p][\"terms\"]\n",
    "\n",
    "def get_session(user_logs: list[dict]) -> str:\n",
    "    \"\"\"Get what type of experiment the user was in\"\"\"\n",
    "    event = [x for x in user_logs if x[\"event\"] == \"SEARCHRESULT_VIEW_URL\"][0]\n",
    "    return event[\"meta\"][\"session\"]\n",
    "\n",
    "\n",
    "def get_session_duration(user_logs: list[dict]) -> int:\n",
    "    \"\"\"Gets how long, in seconds, a user session lasted, from start to end\"\"\"\n",
    "    sorted_logs = sorted(user_logs, key = lambda x: datetime.strptime(x[\"date\"], '%Y-%m-%d %H:%M:%S'))\n",
    "    end_time = p_date(sorted_logs[-1][\"date\"])\n",
    "    start_time = p_date(sorted_logs[0][\"date\"])\n",
    "    return (end_time - start_time).seconds\n",
    "\n",
    "def rebuild_serp(user_log:list[dict], start_event:int) -> dict[str, int]:\n",
    "    \"\"\"Rebuilts a SERP, with documents in each position, for a given query\n",
    "    Returns dict with URL and its position in the SERP.\n",
    "    CAVEAT: If URL appears twice in the serp (may happen due to filtering process), only first occurence counts.\"\"\"\n",
    "    n_events = len(user_log) - start_event\n",
    "    for idx, e in enumerate(user_log[start_event+1:], start = start_event):\n",
    "        if e['event'] == \"SEARCH_QUERY\":\n",
    "            n_events = idx\n",
    "            break\n",
    "    \n",
    "    query_events = sorted(user_log[start_event:start_event+n_events], key = lambda x: datetime.strptime(x[\"date\"], '%Y-%m-%d %H:%M:%S'))\n",
    "    query_events = [x for x in query_events if 'position' in x['meta']]\n",
    "\n",
    "    for k in query_events:\n",
    "        # naive. Filter later.\n",
    "        k['true_position'] = (k['meta']['page']-1)*10 + k['meta']['position']\n",
    "\n",
    "\n",
    "    query_events = sorted(query_events, key = lambda x: x['true_position'])\n",
    "    # Try to rebuild the SERP\n",
    "    serp = {}\n",
    "    docs_so_far = 0\n",
    "    offset = 0 \n",
    "    for ix, e in enumerate(query_events):\n",
    "        meta = e['meta']\n",
    "        url = meta['url']\n",
    "        if url in serp:\n",
    "            continue\n",
    "        serp[url] = e['true_position']\n",
    "\n",
    "    ranking = sorted(serp.items(), key = lambda x : x[1])\n",
    "\n",
    "    return serp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c241f-bdff-4475-9a8d-61773b1c1d79",
   "metadata": {},
   "source": [
    "## Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db4bc1b-460d-4db0-bf90-6a0cec5a4ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c84633a03754df5b7f96f92c52e61c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/127 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = []\n",
    "for count, user in tqdm(enumerate(users), total=len(users)):\n",
    "    user_log = get_all_logs(user) # All user events\n",
    "    user_session = get_session(user_log) # What experiment the user was assigned to\n",
    "    topic = get_topic_title(user_log) # User topic\n",
    "    topic_id = get_topic_id(user_log) # User topic id\n",
    "    \n",
    "    realized_learning_gain = RPL(user_log, topic_id)\n",
    "    absolute_learning_gain = ALG(user_log, topic_id)\n",
    "    time_elapsed = get_session_duration(user_log)\n",
    "\n",
    "\n",
    "    user_data = {\"RPL\":realized_learning_gain, \"ALG\":absolute_learning_gain, \"queries\":[], \"topic_id\":topic_id, \"topic_title\":topic, \"session_duration\": time_elapsed}\n",
    "    current_query = None\n",
    "    queries = 0\n",
    "    query_data = None\n",
    "    # Iterate over log\n",
    "    URL_rankings = {}\n",
    "    for e_idx, e in enumerate(user_log):\n",
    "        meta = e['meta']\n",
    "        if e['event'] == \"SEARCH_QUERY\":\n",
    "            URL_rankings = rebuild_serp(user_log, e_idx)\n",
    "            if query_data: # save previous data\n",
    "                user_data[\"queries\"].append(query_data)\n",
    "            query_data = {\"query_text\" : meta['query'], \"documents_clicked\": []}\n",
    "        #check for hover before click\n",
    "        elif e['event'] == \"SEARCHRESULT_CLICK_URL\":\n",
    "            position = URL_rankings[meta['url']]\n",
    "            query_data['documents_clicked'].append({\"url\":meta['url'], \"position\": position})\n",
    "    dataset.append(user_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0442433e-c204-4b80-91fc-ee7f900584e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(dataset, open(\"../data/logs_with_position.json\", 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DESIRES",
   "language": "python",
   "name": "desires"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
